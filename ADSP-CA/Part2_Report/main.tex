\documentclass[12pt]{article}
\usepackage{tabularx} % extra features for tabular environment
\usepackage{amsmath}  % improve math presentation
\usepackage{graphicx} % takes care of graphic including machinery
\usepackage[margin=1in,letterpaper]{geometry} % decreases margins
\usepackage{cite} % takes care of citations
\usepackage[final]{hyperref} % adds hyper links inside the generated pdf file
\usepackage{leftidx}
\hypersetup{
	colorlinks=true,       % false: boxed links; true: colored links
	linkcolor=blue,        % color of internal links
	citecolor=blue,        % color of links to bibliography
	filecolor=magenta,     % color of file links
	urlcolor=blue         
}
\usepackage{paralist}
\usepackage{tikz}
\usetikzlibrary{dsp,chains}
\DeclareMathAlphabet{\mathpzc}{OT1}{pzc}{m}{it}
\newcommand{\z}{\mathpzc{z}}
\usepackage{amsmath,bm}
\usepackage{schemabloc}

\usetikzlibrary{circuits}
\usepackage{verbatim}

\begin{document}

\title{Assignment Report of ADSP Part 2\\
	 }
\author{Liu Xiangyu G1802061L}
\date{\today}
\maketitle

\noindent
Q1.a)
Given,
\begin{equation}
	x[n]=s[n]+w[n]
	\label{eq:xn}
\end{equation}
\begin{equation}
	s[n]=0.8s[n-1]+v[n]
	\label{eq:sn}
\end{equation}
from eq.(\ref{eq:sn}), the power spectral density of s[n],
\begin{equation}
	\label{eq:psdsn}
	\begin{array}{lll}
		\Gamma_{ss}(z)&=&\sigma_{v}^{2}H(z)H(z^{-1})\\
		&=&\sigma_{v}^{2}\frac{1}{1-0.8z^{-1}}\frac{1}{1-0.8z}
	\end{array}
\end{equation}
By taking the inverse Z-transform, the autocorrelation functions
\begin{equation}
\label{eq:rss}
	\gamma_{ss}[k]=0.8^{|k|}
\end{equation}
\begin{equation}
\label{eq:rxx}
	\gamma_{xx}[k]=\gamma_{ss}[k]+\gamma_{ww}[k]=0.8^{|k|}+\delta[k]
\end{equation}

\noindent
b)
Solve the following normal equations:
\begin{equation}
	\left [
	\begin{array}{cc}
		\gamma_{xx}[0]&\gamma_{xx}[-1]\\
		\gamma_{xx}[1]&\gamma_{xx}[0]
	\end{array}
	\right ]
	\left[
	\begin{array}{c}
	h[0]\\
	h[1]
	\end{array}
	\right ]
	=\left[
	\begin{array}{c}
		\gamma_{ss}[0]\\
		\gamma_{ss}[1]
	\end{array}
	\right]
\end{equation}
\begin{equation}
	\left[
	\begin{array}{cc}
		2&0.8\\
		0.8&2
	\end{array}
	\right]
	\left[
	\begin{array}{c}
		h[0]\\
		h[1]
	\end{array}
	\right]
	=
	\left[
	\begin{array}{c}
		1\\
		0.8
	\end{array}
	\right]
\end{equation}
Therefore,
\begin{equation}
\label{eq:h}
	h_{opt}[0]=0.405, h_{opt}[1]=0.238
\end{equation}


\noindent
c)
Hence,
\begin{equation}
	\varepsilon_{2}^{h}=\min\varepsilon_{2}^{h}=\gamma_{ss}[0]-
	\left[
	\begin{array}{cc}
		\gamma_{ss}[0]&\gamma_{ss}[1]
	\end{array}
	\right]
	\left[
	\begin{array}
		{c}
		h[0]\\
		h[1]
	\end{array}
	\right]=0.405
\end{equation}

\noindent
Q2.a)
A linear adaptive filtering algorithm involves two basic processes: 
\begin{inparaenum}[(1)]
	\item a filtering process designed to produce an output in response to a sequence of input data, and
	\item an adaptive process, the purpose of which is to provide a mechanism for the adaptive control of an adjustable set of parameters used in the filtering process.
\end{inparaenum}

\noindent
b)
The implementation of the adaptive noise canceller is demonstrated in fq.(\ref{fg:anc}).
\begin{figure}
\begin{center}

\begin{tikzpicture}
	\sbEntree{E}
	\sbComp[17]{a}{E}
		 \sbRelier{E}{a}
	\sbSortie[5]{S1}{a}
		\sbRelier{a}{S1}
		\sbNomLien[0.8]{S1}{Output}
    \sbDecaleNoeudy{a}{v}

    \sbDecaleNoeudy[10]{a}{f}

    \sbBlocr{r2}{Adaptive FIR Filter}{v}
    \sbBlocr{r3}{Adaptive Algorithm}{f}
	\sbRelierxy{r2}{a}
	\sbRelieryx{a-S1}{r3}
	\sbRelier{r3}{r2}
	
        \sbDecaleNoeudy{E}{u}
        	\sbRelier{u}{r2}
        	
 \sbNomLien[0.8]{E}{$y(n)$} 
 \sbNomLien[0.8]{u}{$v(n)$}

\end{tikzpicture}

\end{center}
\caption{Adaptive Noise Canceller}
\label{fg:anc}

\end{figure}

The LMS algorithm is given by,
\begin{equation}
\begin{array}{lr}
		\bm{h}_{M}(n+1)=\bm{h}_{M}(n)+\mu e(n)\bm{X}_{M}^{*}(n), & n=0,1,2,...
\end{array}
\end{equation}
where, 
\begin{enumerate}
	\item $\mathbf{h}_{M}(n)$ is the matrices of estimates of the true coefficients,
	\item $\mu$ is a fixed step size,
	\item $e(n)=d(n)-\hat{d}(n)$,
	\item $\bm{X}_{M}(n)$ is the set of M signal samples in the filter at the $n^{th}$ iteration.
\end{enumerate}
Therefore, the adaptive FIR filter to estimate the noise $\hat{w}_{2}(n)$ works as,
\begin{equation}
	\hat{w}_{2}(n)=\sum_{m=0}^{M}{h_{M}(m)v(n-m)}
\end{equation}

\noindent
c)
The convergence of the mean of the coefficient vector in the LMS algorithm depends on the range of $\mu$,
\begin{equation}
	0<\mu<\frac{2}{\lambda_{max}}
\end{equation}
where $lambda_{max}$ is the largest eigenvalue of $\Gamma_{M}$,
\begin{equation}
	\lambda_{max}<\sum_{k=0}^{M-1}{\lambda_{k}}=trace\Gamma_{M}=M\gamma_{xx}[0]
\end{equation}
Given the input white noise signal has zero mean and variance $w^{2}$, 
\begin{equation}
	\lambda_{max}<M\gamma_{xx}[0]=M\sigma^{2}\delta[0]=M\sigma^{2}
\end{equation}
Therefore, the condition for convergence is when the selected fixed step size $\mu$ is less than the upper bound,
\begin{equation}
	\mu<\frac{2}{M\sigma^{2}}
\end{equation}

\noindent
Q3.
Given $x(n)=s(n)+w(n)$, 
\begin{equation}
	\gamma_{xx}[m]=\gamma_{ss}[m]+\gamma_{ww}[m]=\gamma_{ss}[m]+\sigma_{w}^{2}\delta[m]
\end{equation}
\begin{equation}
	\Gamma_{xx}(z)=\Gamma_{ss}(z)+\Gamma_{ww}(z)=\frac{\sigma_{s}^{2}}{|A(z)|^{2}}+\sigma_{w}^{2}=\frac{\sigma_{s}^{2}+\sigma_{w}^{2}|A(z)|^{2}}{|A(z)|^{2}}
\end{equation}
%Let $\alpha^{2}={\sigma_{s}^{2}}{\sigma_{w}^{2}}$,
%\begin{equation}
%		\Gamma_{xx}(z=\sigma_{s}\frac{1+\alpha^{2}|A(z)|^{2}}{|A(z)|^{2}}
%\end{equation}
To model $x(n)$ as ARMA(2,2) process, the power density spectrum of $x(n)$ needs to have the formation:
\begin{equation}
	\hat{\Gamma}_{xx}(z)=\hat{\sigma}_{x}\frac{\hat{B}(z)\hat{B}(z^{-1})}{\hat{A}(z)\hat{A}(z^{-1})}
\end{equation}
where,
\begin{equation}
\begin{split}
	\hat{A}(z)=a_{0}+a_{1}z^{-1}+a_{2}z^{-2}\\
	\hat{B}(z)=b_{0}+b_{1}z^{-1}+b_{2}z^{-2}
\end{split}
\end{equation}
In this case, since $s(n)$ is given as an AR(2) process, we only need to find $B(z)$ so that,
\begin{equation}
\label{eq:bbdesired}
	B(z)B(z^{-1})=\sigma_{s}^{2}+\sigma_{w}^{2}|A(z)|^{2}
\end{equation}
Therefore, let 
\begin{equation}
\label{eq:hatbc}
	B(z)=c+\sigma_{w}A(z)
\end{equation}
where $c$ is a constant to determine. If there exists a value of $c$ that makes $\hat{B}(z)\hat{B}(z^{-1})$ equal to $\sigma_{s}^{2}+\sigma_{w}^{2}|A(z)|^{2}$, x(n) can be modelled as an ARMA(2,2) process. 
Based on eq.(\ref{eq:hatbc}), 
\begin{equation}
\label{eq:hatbext}
\begin{split}
		B(z)B(z^{-1})&=c^{2}+c\sigma_{w}(A(z)+A(z^{-1}))+\sigma_{w}^{2}|A(z)|^{2}\\
		&=c^{2}+2c\sigma_{w}Re\{A(z)\}+\sigma_{w}^{2}|A(z)|^{2}
\end{split}
\end{equation}
Considering eq.(\ref{eq:bbdesired}) equal to eq.(\ref{eq:hatbext}), the proper c can be obtained,
\begin{equation}
	\hat{c}=\sqrt{\sigma_{s}^{2}+\sigma_{w}^{2}Re^{2}\{A(z)\}}-\sigma_{w}Re\{A(z)\}
\end{equation}
With $c$ selected as above, the condition in eq.(\ref{eq:bbdesired}) is satisfied, and x(n) is an ARMA(2,2) process with A(z) given and B(z) as,
\begin{equation}
	B(z)=\hat{c}+\sigma_{w}A(z)
\end{equation}

\end{document}
